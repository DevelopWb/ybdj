package YangTalkback.Codec;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.nio.ByteBuffer;

import YangTalkback.Codec.FFCodec.AVCodecCfg;
import YangTalkback.Codec.FFCodec.DFrame;
import YangTalkback.Codec.FFCodec.FFCode;
import YangTalkback.Codec.FFCodec.FFCodecType;
import YangTalkback.Codec.FFCodec.FFObj;
import YangTalkback.Media.MediaFrame;
import YangTalkback.Media.VideoDisplayFrame;
import android.R.bool;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.Bitmap.Config;

import h264.com.VView;
import AXLib.Utility.Console;
import AXLib.Utility.Event;
import AXLib.Utility.IDisposable;
import AXLib.Utility.Queue;
import AXLib.Utility.RuntimeExceptionEx;

//H264解码器,没有用到
public class H264AndroidDecoder extends VView implements IDisposable {

	// 图片像素存放区域
	protected byte[] mPixel = null;
	// 图片存放内存区间
	protected ByteBuffer bmpBuffer = null;
	// 解码后的图片
	protected Bitmap VideoBit = null;

	// 视频数据接收缓冲区
	protected Queue<MediaFrame> qFrame = null;
	// 标识解码线程是否正在工作中
	protected boolean decodeThreadWorking = false;
	// 最大缓冲时间
	protected final int MaxBufferTime = 1;

	// 解码一桢图片的事件
	// public final Event<Bitmap> Decoded = new Event<Bitmap>();

	public final Event<Exception> Error = new Event<Exception>();

	protected boolean inited = false;

	// 初始化
	private void Init(MediaFrame mf) {
		if (mf == null || mf.nIsKeyFrame == 0)
			throw new RuntimeException("初始化解码器出错，非关键帧不能初始化解码器");
		if (mf.nWidth <= 0 || mf.nHeight <= 0)
			throw new RuntimeException("初始化解码器出错，长度或宽度错误");
		int nWidth = mf.nWidth;
		int nHeight = mf.nHeight;

		mPixel = new byte[nWidth * nHeight * 3];
		bmpBuffer = ByteBuffer.wrap(mPixel);
		VideoBit = Bitmap.createBitmap(nWidth, nHeight, Config.RGB_565);
		try {
			InitDecoder(nWidth, nHeight);
		} catch (Throwable e) {
			String stackString = RuntimeExceptionEx.GetStackTraceString(e);
			throw RuntimeExceptionEx.Create(e);
		}
		inited = true;
	}

	public VideoDisplayFrame Deocde(MediaFrame mf) throws Exception {
		if (!inited && mf.nIsKeyFrame == 1)
			Init(mf);
		if (inited) {
			int dsize = -1;
			try {
				synchronized (VideoBit) {
					dsize = DecoderNal(mf.Data, mf.nSize, mPixel);
				}
			} catch (Throwable e) {
				String stackString = RuntimeExceptionEx.GetStackTraceString(e);
				throw RuntimeExceptionEx.Create(e);
			}
			if (dsize != -1) {
				VideoBit.copyPixelsFromBuffer(bmpBuffer);
				return new VideoDisplayFrame(VideoBit, mf.nTimetick);
				// OnDecoded(VideoBit);
			}
		}
		return null;
	}

	// // 引发解码完成事件
	// private void OnDecoded(Bitmap bitmap) {
	// if (Decoded.getHandleCount() >= 0)
	// Decoded.Trigger(this, bitmap);
	// }

	@Override
	public void Dispose() {
		if (inited)
			UninitDecoder();
	}
}
